[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
Loading dataset:   3%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                                                                                                                     | 13/465 [00:00<00:03, 126.26it/s]
GPU ID:  0

Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:03<00:00, 122.56it/s]


Loading dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 465/465 [00:02<00:00, 166.20it/s]
eta: 0:11:31  epoch: 2  step: 2001  rgb_loss: 0.0991  depth_loss: 0.0860  joint_loss: 0.1651  cross_entropy_loss: 0.8288  eikonal_loss: 0.1414  loss: 0.6219  beta: 0.0205  theta: -0.1049  data: 0.0160  batch: 0.6921  lr: 0.000456  max_mem: 9152
eta: 0:11:04  epoch: 2  step: 2002  rgb_loss: 0.1467  depth_loss: 0.0759  joint_loss: 0.3292  cross_entropy_loss: 0.9419  eikonal_loss: 0.1757  loss: 0.7276  beta: 0.0205  theta: -0.1048  data: 0.0158  batch: 0.6658  lr: 0.000456  max_mem: 9185
eta: 0:10:52  epoch: 2  step: 2003  rgb_loss: 0.1327  depth_loss: 0.0709  joint_loss: 0.2745  cross_entropy_loss: 0.8827  eikonal_loss: 0.1460  loss: 0.6734  beta: 0.0205  theta: -0.1048  data: 0.0158  batch: 0.6550  lr: 0.000456  max_mem: 9186
eta: 0:10:47  epoch: 2  step: 2004  rgb_loss: 0.1411  depth_loss: 0.0884  joint_loss: 0.2983  cross_entropy_loss: 0.8699  eikonal_loss: 0.1990  loss: 0.6992  beta: 0.0205  theta: -0.1048  data: 0.0157  batch: 0.6502  lr: 0.000456  max_mem: 9187
eta: 0:10:44  epoch: 2  step: 2005  rgb_loss: 0.1318  depth_loss: 0.0886  joint_loss: 0.2838  cross_entropy_loss: 0.8380  eikonal_loss: 0.1748  loss: 0.6710  beta: 0.0205  theta: -0.1048  data: 0.0159  batch: 0.6474  lr: 0.000456  max_mem: 9188
eta: 0:10:41  epoch: 2  step: 2006  rgb_loss: 0.1376  depth_loss: 0.0873  joint_loss: 0.2907  cross_entropy_loss: 0.8665  eikonal_loss: 0.1626  loss: 0.6890  beta: 0.0205  theta: -0.1048  data: 0.0158  batch: 0.6453  lr: 0.000456  max_mem: 9188
eta: 0:10:39  epoch: 2  step: 2007  rgb_loss: 0.1419  depth_loss: 0.0959  joint_loss: 0.2574  cross_entropy_loss: 0.8463  eikonal_loss: 0.1877  loss: 0.6926  beta: 0.0205  theta: -0.1048  data: 0.0159  batch: 0.6438  lr: 0.000456  max_mem: 9190
Traceback (most recent call last):
  File "train_net.py", line 129, in <module>
    main()
  File "train_net.py", line 125, in main
    train(cfg, network)
  File "train_net.py", line 59, in train
    trainer.train(epoch, train_loader, optimizer, recorder)
  File "/home/gskim/3D/manhattan_sdf_renew/lib/train/trainers/trainer.py", line 90, in train
    loss.backward()
  File "/home/gskim/anaconda3/envs/manhattan/lib/python3.7/site-packages/torch/tensor.py", line 185, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/gskim/anaconda3/envs/manhattan/lib/python3.7/site-packages/torch/autograd/__init__.py", line 127, in backward
    allow_unreachable=True)  # allow_unreachable flag
KeyboardInterrupt